import numpy as np
import os
from tqdm import tqdm
import yaml
from typing import Dict, Any, List  # æ·»åŠ  List å¯¼å…¥
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib import gridspec
import warnings

# å¿½ç•¥matplotlibçš„è­¦å‘Š
warnings.filterwarnings('ignore', category=UserWarning)

# è®¾ç½®ä¸­æ–‡å­—ä½“å’Œå›¾è¡¨æ ·å¼
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = [12, 8]
plt.rcParams['figure.dpi'] = 100

# ç¡¬ç¼–ç é…ç½®ï¼Œé¿å…æ–‡ä»¶è¯»å–é—®é¢˜
DEFAULT_CONFIG = {
    'simulation': {
        'sample_rate': 100000,
        'duration': 0.1,
        'num_traces': 64,
        'trace_length': 1024
    },
    'source': {
        'frequency': 10000,
        'bandwidth': 8000,
        'pulse_type': 'ricker'
    },
    'sediment': {
        'min_layers': 1,
        'max_layers': 8,
        'thickness_range': [0.1, 5.0],
        'density_range': [1200, 2200],
        'velocity_range': [1450, 2200],
        'attenuation_range': [0.1, 5.0]
    },
    'sediment_types': {
        'clay': {
            'density': [1500, 1700],
            'velocity': [1470, 1550],
            'attenuation': [0.5, 1.5]
        },
        'silt': {
            'density': [1650, 1850],
            'velocity': [1550, 1650],
            'attenuation': [1.0, 2.5]
        },
        'sand': {
            'density': [1800, 2100],
            'velocity': [1650, 1850],
            'attenuation': [2.0, 4.0]
        },
        'gravel': {
            'density': [1900, 2200],
            'velocity': [1800, 2200],
            'attenuation': [3.0, 5.0]
        }
    },
    'noise': {
        'snr_range': [10, 30],
        'reverberation_level': 0.1,
        'electronic_noise': 0.05
    }
}

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
try:
    from core.sediment_generator import SedimentModelGenerator
    from core.acoustic_simulator import AcousticSimulator
    from core.sensor_simulator import SensorSimulator
    from core.data_augmentation import DataAugmentation
    from utils.file_io import DataSaver
except ImportError as e:
    print(f"å¯¼å…¥æ¨¡å—æ—¶å‡ºé”™: {e}")
    print("è¯·ç¡®ä¿ä»¥ä¸‹æ¨¡å—å­˜åœ¨:")
    print("1. core/sediment_generator.py")
    print("2. core/acoustic_simulator.py")
    print("3. core/sensor_simulator.py")
    print("4. core/data_augmentation.py")
    print("5. utils/file_io.py")
    print("\næ­£åœ¨åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆå™¨ä»¥è¿›è¡Œæµ‹è¯•...")
    
    # åˆ›å»ºæ¨¡æ‹Ÿç±»ä»¥ä¾¿ç»§ç»­è¿è¡Œ
    class SedimentModelGenerator:
        def __init__(self):
            pass
        def generate_layered_model(self):
            return {'model_id': 'test', 'layers': [], 'total_depth': 10.0}
        def add_geological_features(self, model):
            return model
        def generate_reflection_coefficients(self, model):
            return np.random.randn(DEFAULT_CONFIG['simulation']['trace_length'])
        def generate_segmentation_mask(self, model):
            return np.zeros(DEFAULT_CONFIG['simulation']['trace_length'], dtype=np.int32)
    
    class AcousticSimulator:
        def __init__(self, config):
            self.config = config
        def convolutional_model(self, reflection_series):
            return reflection_series * 0.8 + np.random.normal(0, 0.1, len(reflection_series))
    
    class SensorSimulator:
        def __init__(self, config):
            self.config = config
        def add_noise(self, data):
            return data + np.random.normal(0, 0.05, len(data))
    
    class DataAugmentation:
        def __init__(self, config):
            self.config = config
        def apply_augmentation(self, data, mask):
            return data, mask
    
    class DataSaver:
        def __init__(self, path):
            self.path = path
            os.makedirs(path, exist_ok=True)
        def save_training_sample(self, data, labels, metadata, filename):
            print(f"ä¿å­˜æ ·æœ¬ {filename}")
        def save_dataset_info(self, info):
            print("ä¿å­˜æ•°æ®é›†ä¿¡æ¯")

class Visualizer:
    """å¯è§†åŒ–å·¥å…·ç±»"""
    
    @staticmethod
    def plot_single_sample(sample: Dict[str, Any], sample_id: int = 0, save_path: str = None):
        """ç»˜åˆ¶å•ä¸ªæ ·æœ¬çš„å¯è§†åŒ–å›¾è¡¨"""
        data = sample['data']
        labels = sample['labels']
        metadata = sample['metadata']
        
        # åˆ›å»ºå¤šå­å›¾
        fig = plt.figure(figsize=(16, 12))
        gs = gridspec.GridSpec(4, 3, figure=fig, height_ratios=[2, 2, 1.5, 1])
        
        # 1. å£°å‘æ•°æ®æ³¢å½¢å›¾
        ax1 = fig.add_subplot(gs[0, :])
        t = np.arange(len(data)) / DEFAULT_CONFIG['simulation']['sample_rate']
        ax1.plot(t, data, 'b-', linewidth=1, alpha=0.8, label='å£°å‘æ•°æ®')
        ax1.set_xlabel('æ—¶é—´ (s)', fontsize=12)
        ax1.set_ylabel('æŒ¯å¹…', fontsize=12)
        ax1.set_title(f'æ ·æœ¬ {sample_id} - å£°å‘æ•°æ®æ³¢å½¢', fontsize=14, fontweight='bold')
        ax1.grid(True, alpha=0.3)
        ax1.legend(loc='upper right')
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        stats_text = f"å‡å€¼: {np.mean(data):.4f}, æ ‡å‡†å·®: {np.std(data):.4f}, å³°å€¼: {np.max(np.abs(data)):.4f}"
        ax1.text(0.02, 0.95, stats_text, transform=ax1.transAxes, 
                fontsize=10, verticalalignment='top',
                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
        
        # 2. åˆ†å‰²æ©ç å›¾
        ax2 = fig.add_subplot(gs[1, :])
        
        # ç±»åˆ«é¢œè‰²æ˜ å°„
        class_colors = {
            0: '#1f77b4',  # æµ·æ°´ - è“è‰²
            1: '#2ca02c',  # clay - ç»¿è‰²
            2: '#ff7f0e',  # silt - æ©™è‰²
            3: '#d62728',  # sand - çº¢è‰²
            4: '#9467bd',  # gravel - ç´«è‰²
            5: '#8c564b',  # mixed - æ£•è‰²
            6: '#e377c2',  # gas_pocket - ç²‰è‰²
            7: '#7f7f7f',  # buried_object - ç°è‰²
            8: '#bcbd22',  # fault - é»„ç»¿è‰²
            9: '#17becf',  # bioturbation - é’è‰²
            10: '#ff9896'  # irregular_interface - æµ…çº¢è‰²
        }
        
        # ç±»åˆ«æ ‡ç­¾
        class_labels = {
            0: 'æµ·æ°´',
            1: 'ç²˜åœŸ',
            2: 'ç²‰ç ‚',
            3: 'æ²™',
            4: 'ç ¾çŸ³',
            5: 'æ··åˆ',
            6: 'æ°”åŒ…',
            7: 'åŸ‹è—ç‰©ä½“',
            8: 'æ–­å±‚',
            9: 'ç”Ÿç‰©æ‰°åŠ¨',
            10: 'ä¸è§„åˆ™ç•Œé¢'
        }
        
        # ç»˜åˆ¶åˆ†å‰²æ©ç 
        for class_id in np.unique(labels):
            if class_id in class_colors:
                mask_indices = np.where(labels == class_id)[0]
                if len(mask_indices) > 0:
                    ax2.scatter(t[mask_indices], [class_id] * len(mask_indices), 
                              color=class_colors[class_id], s=10, alpha=0.7,
                              label=class_labels.get(class_id, f'ç±»åˆ«{class_id}'))
        
        ax2.set_xlabel('æ—¶é—´ (s)', fontsize=12)
        ax2.set_ylabel('ç±»åˆ«', fontsize=12)
        ax2.set_title('åˆ†å‰²æ©ç æ ‡æ³¨', fontsize=14, fontweight='bold')
        ax2.set_yticks(list(class_labels.keys()))
        ax2.set_yticklabels([class_labels.get(i, f'ç±»{i}') for i in class_labels.keys()])
        ax2.grid(True, alpha=0.3)
        ax2.legend(loc='upper right', fontsize=9)
        
        # 3. é¢‘è°±åˆ†æ
        ax3 = fig.add_subplot(gs[2, 0])
        if len(data) > 1:
            fft_data = np.fft.fft(data)
            freq = np.fft.fftfreq(len(data), 1/DEFAULT_CONFIG['simulation']['sample_rate'])
            positive_freq = freq[:len(freq)//2]
            positive_fft = np.abs(fft_data[:len(freq)//2])
            ax3.plot(positive_freq / 1000, positive_fft, 'g-', linewidth=1, alpha=0.7)
            ax3.set_xlabel('é¢‘ç‡ (kHz)', fontsize=11)
            ax3.set_ylabel('å¹…å€¼', fontsize=11)
            ax3.set_title('é¢‘è°±åˆ†æ', fontsize=12, fontweight='bold')
            ax3.grid(True, alpha=0.3)
            
            # æ ‡è®°ä¸»é¢‘
            if len(positive_fft) > 0:
                peak_freq_idx = np.argmax(positive_fft[1:]) + 1
                peak_freq = positive_freq[peak_freq_idx] / 1000
                peak_mag = positive_fft[peak_freq_idx]
                ax3.plot(peak_freq, peak_mag, 'ro', markersize=8)
                ax3.text(peak_freq, peak_mag, f' {peak_freq:.1f} kHz', 
                        fontsize=10, verticalalignment='bottom')
        
        # 4. ç›´æ–¹å›¾
        ax4 = fig.add_subplot(gs[2, 1])
        ax4.hist(data, bins=50, alpha=0.7, color='skyblue', edgecolor='black')
        ax4.set_xlabel('æŒ¯å¹…', fontsize=11)
        ax4.set_ylabel('é¢‘æ•°', fontsize=11)
        ax4.set_title('æŒ¯å¹…åˆ†å¸ƒ', fontsize=12, fontweight='bold')
        ax4.grid(True, alpha=0.3)
        
        # æ·»åŠ åˆ†å¸ƒå‚æ•°
        skewness = np.mean((data - np.mean(data))**3) / (np.std(data)**3)
        kurtosis = np.mean((data - np.mean(data))**4) / (np.std(data)**4)
        ax4.text(0.02, 0.95, f'ååº¦: {skewness:.2f}\nå³°åº¦: {kurtosis:.2f}', 
                transform=ax4.transAxes, fontsize=9,
                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
        
        # 5. è‡ªç›¸å…³å›¾
        ax5 = fig.add_subplot(gs[2, 2])
        autocorr = np.correlate(data - np.mean(data), data - np.mean(data), mode='full')
        autocorr = autocorr[len(autocorr)//2:]
        autocorr = autocorr[:min(200, len(autocorr))]  # åªæ˜¾ç¤ºå‰200ä¸ªç‚¹
        ax5.plot(autocorr, 'm-', linewidth=1.5, alpha=0.7)
        ax5.set_xlabel('å»¶è¿Ÿ', fontsize=11)
        ax5.set_ylabel('è‡ªç›¸å…³', fontsize=11)
        ax5.set_title('è‡ªç›¸å…³å‡½æ•°', fontsize=12, fontweight='bold')
        ax5.grid(True, alpha=0.3)
        
        # 6. æ¨¡å‹ä¿¡æ¯è¡¨æ ¼
        ax6 = fig.add_subplot(gs[3, :])
        ax6.axis('tight')
        ax6.axis('off')
        
        # å‡†å¤‡è¡¨æ ¼æ•°æ®
        table_data = []
        table_data.append(['æ¨¡å‹ID', metadata.get('model_id', 'N/A')])
        table_data.append(['æ ·æœ¬ID', metadata.get('sample_id', 'N/A')])
        table_data.append(['å±‚æ•°', metadata.get('num_layers', 'N/A')])
        table_data.append(['æ€»æ·±åº¦', f"{metadata.get('total_depth', 0):.2f} m"])
        
        if 'layer_info' in metadata and len(metadata['layer_info']) > 0:
            # ç»Ÿè®¡æ²‰ç§¯ç‰©ç±»å‹
            sediment_types = {}
            for layer in metadata['layer_info']:
                sed_type = layer.get('sediment_type', 'unknown')
                sediment_types[sed_type] = sediment_types.get(sed_type, 0) + 1
            
            type_str = ', '.join([f"{k}:{v}" for k, v in sediment_types.items()])
            table_data.append(['æ²‰ç§¯ç‰©åˆ†å¸ƒ', type_str])
        
        if 'features' in metadata and len(metadata['features']) > 0:
            feature_types = {}
            for feature in metadata['features']:
                ftype = feature.get('type', 'unknown')
                feature_types[ftype] = feature_types.get(ftype, 0) + 1
            
            feature_str = ', '.join([f"{k}:{v}" for k, v in feature_types.items()])
            table_data.append(['åœ°è´¨ç‰¹å¾', feature_str])
        
        # æ·»åŠ æ•°æ®ç»Ÿè®¡
        table_data.append(['æ•°æ®é•¿åº¦', f"{len(data)} é‡‡æ ·ç‚¹"])
        table_data.append(['é‡‡æ ·ç‡', f"{DEFAULT_CONFIG['simulation']['sample_rate']} Hz"])
        table_data.append(['æ—¶é—´èŒƒå›´', f"{t[-1]:.3f} s"])
        
        # åˆ›å»ºè¡¨æ ¼
        table = ax6.table(cellText=table_data, 
                         cellLoc='left',
                         loc='center',
                         colWidths=[0.2, 0.8])
        
        table.auto_set_font_size(False)
        table.set_fontsize(10)
        table.scale(1, 2)
        
        # è®¾ç½®è¡¨æ ¼æ ·å¼
        for i in range(len(table_data)):
            table[(i, 0)].set_facecolor('#f0f0f0')
            table[(i, 1)].set_facecolor('#fafafa')
        
        plt.suptitle(f'å£°å‘ä»¿çœŸæ ·æœ¬å¯è§†åŒ– - æ ·æœ¬ {sample_id}', fontsize=16, fontweight='bold', y=0.98)
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=150, bbox_inches='tight')
            print(f"å›¾è¡¨å·²ä¿å­˜åˆ°: {save_path}")
        
        plt.show()
        plt.close()
    
    @staticmethod
    def plot_dataset_summary(dataset_info: Dict[str, Any], samples_metadata: List[Dict[str, Any]], 
                           output_dir: str = "visualization"):
        """ç»˜åˆ¶æ•°æ®é›†æ€»ç»“å›¾è¡¨"""
        os.makedirs(output_dir, exist_ok=True)
        
        # æå–ç»Ÿè®¡ä¿¡æ¯
        num_layers_list = [meta.get('num_layers', 0) for meta in samples_metadata]
        total_depth_list = [meta.get('total_depth', 0) for meta in samples_metadata]
        
        # ç»Ÿè®¡æ²‰ç§¯ç‰©ç±»å‹åˆ†å¸ƒ
        sediment_counts = {}
        feature_counts = {}
        
        for meta in samples_metadata:
            # æ²‰ç§¯ç‰©ç±»å‹
            if 'layer_info' in meta:
                for layer in meta['layer_info']:
                    sed_type = layer.get('sediment_type', 'unknown')
                    sediment_counts[sed_type] = sediment_counts.get(sed_type, 0) + 1
            
            # åœ°è´¨ç‰¹å¾
            if 'features' in meta:
                for feature in meta['features']:
                    ftype = feature.get('type', 'unknown')
                    feature_counts[ftype] = feature_counts.get(ftype, 0) + 1
        
        # åˆ›å»ºæ€»ç»“å›¾è¡¨
        fig = plt.figure(figsize=(18, 12))
        
        # 1. å±‚æ•°åˆ†å¸ƒ
        ax1 = plt.subplot(2, 3, 1)
        unique_layers, layer_counts = np.unique(num_layers_list, return_counts=True)
        ax1.bar(unique_layers, layer_counts, color='skyblue', edgecolor='black')
        ax1.set_xlabel('å±‚æ•°', fontsize=12)
        ax1.set_ylabel('æ ·æœ¬æ•°é‡', fontsize=12)
        ax1.set_title('æ²‰ç§¯å±‚å±‚æ•°åˆ†å¸ƒ', fontsize=14, fontweight='bold')
        ax1.grid(True, alpha=0.3, axis='y')
        
        # åœ¨æŸ±å­ä¸Šæ·»åŠ æ•°å­—
        for i, count in enumerate(layer_counts):
            ax1.text(unique_layers[i], count + 0.1, str(int(count)), 
                    ha='center', va='bottom', fontsize=10)
        
        # 2. æ·±åº¦åˆ†å¸ƒ
        ax2 = plt.subplot(2, 3, 2)
        ax2.hist(total_depth_list, bins=15, alpha=0.7, color='lightgreen', edgecolor='black')
        ax2.set_xlabel('æ€»æ·±åº¦ (m)', fontsize=12)
        ax2.set_ylabel('æ ·æœ¬æ•°é‡', fontsize=12)
        ax2.set_title('æ€»æ·±åº¦åˆ†å¸ƒ', fontsize=14, fontweight='bold')
        ax2.grid(True, alpha=0.3, axis='y')
        
        # æ·»åŠ å¹³å‡æ·±åº¦çº¿
        avg_depth = np.mean(total_depth_list)
        ax2.axvline(avg_depth, color='red', linestyle='--', linewidth=2, 
                   label=f'å¹³å‡æ·±åº¦: {avg_depth:.2f} m')
        ax2.legend()
        
        # 3. æ²‰ç§¯ç‰©ç±»å‹åˆ†å¸ƒ
        ax3 = plt.subplot(2, 3, 3)
        if sediment_counts:
            sediment_types = list(sediment_counts.keys())
            counts = list(sediment_counts.values())
            
            colors = plt.cm.Set3(np.linspace(0, 1, len(sediment_types)))
            wedges, texts, autotexts = ax3.pie(counts, labels=sediment_types, autopct='%1.1f%%',
                                              colors=colors, startangle=90)
            
            # ç¾åŒ–ç™¾åˆ†æ¯”æ–‡æœ¬
            for autotext in autotexts:
                autotext.set_color('black')
                autotext.set_fontsize(10)
                autotext.set_fontweight('bold')
            
            ax3.set_title('æ²‰ç§¯ç‰©ç±»å‹åˆ†å¸ƒ', fontsize=14, fontweight='bold')
        
        # 4. åœ°è´¨ç‰¹å¾åˆ†å¸ƒ
        ax4 = plt.subplot(2, 3, 4)
        if feature_counts:
            feature_types = list(feature_counts.keys())
            fcounts = list(feature_counts.values())
            
            y_pos = np.arange(len(feature_types))
            bars = ax4.barh(y_pos, fcounts, color='lightcoral', edgecolor='black')
            ax4.set_yticks(y_pos)
            ax4.set_yticklabels(feature_types)
            ax4.set_xlabel('å‡ºç°æ¬¡æ•°', fontsize=12)
            ax4.set_title('åœ°è´¨ç‰¹å¾åˆ†å¸ƒ', fontsize=14, fontweight='bold')
            ax4.grid(True, alpha=0.3, axis='x')
            
            # åœ¨æ¡å½¢ä¸Šæ·»åŠ æ•°å­—
            for i, bar in enumerate(bars):
                width = bar.get_width()
                ax4.text(width + 0.1, bar.get_y() + bar.get_height()/2, 
                        str(int(width)), ha='left', va='center', fontsize=10)
        
        # 5. æ·±åº¦ vs å±‚æ•° æ•£ç‚¹å›¾
        ax5 = plt.subplot(2, 3, 5)
        scatter = ax5.scatter(num_layers_list, total_depth_list, 
                            c=total_depth_list, cmap='viridis', alpha=0.6, s=50)
        ax5.set_xlabel('å±‚æ•°', fontsize=12)
        ax5.set_ylabel('æ€»æ·±åº¦ (m)', fontsize=12)
        ax5.set_title('å±‚æ•°ä¸æ·±åº¦å…³ç³»', fontsize=14, fontweight='bold')
        ax5.grid(True, alpha=0.3)
        
        # æ·»åŠ é¢œè‰²æ¡
        plt.colorbar(scatter, ax=ax5, label='æ·±åº¦ (m)')
        
        # 6. æ•°æ®é›†ä¿¡æ¯è¡¨æ ¼
        ax6 = plt.subplot(2, 3, 6)
        ax6.axis('tight')
        ax6.axis('off')
        
        table_data = [
            ['æ€»æ ·æœ¬æ•°', str(dataset_info.get('total_samples', 0))],
            ['åˆ›å»ºæ—¥æœŸ', dataset_info.get('creation_date', 'N/A')],
            ['å¹³å‡å±‚æ•°', f"{np.mean(num_layers_list):.2f}"],
            ['å¹³å‡æ·±åº¦', f"{np.mean(total_depth_list):.2f} m"],
            ['æœ€å¤§æ·±åº¦', f"{np.max(total_depth_list):.2f} m"],
            ['æœ€å°æ·±åº¦', f"{np.min(total_depth_list):.2f} m"],
            ['æ²‰ç§¯ç‰©ç±»å‹æ•°', str(len(sediment_counts))],
            ['åœ°è´¨ç‰¹å¾ç±»å‹æ•°', str(len(feature_counts))]
        ]
        
        table = ax6.table(cellText=table_data, 
                         cellLoc='left',
                         loc='center',
                         colWidths=[0.4, 0.6])
        
        table.auto_set_font_size(False)
        table.set_fontsize(10)
        table.scale(1, 2)
        
        # è®¾ç½®è¡¨æ ¼æ ·å¼
        for i in range(len(table_data)):
            table[(i, 0)].set_facecolor('#e0e0e0')
            table[(i, 1)].set_facecolor('#f5f5f5')
        
        plt.suptitle('å£°å‘ä»¿çœŸæ•°æ®é›†ç»Ÿè®¡æ€»ç»“', fontsize=18, fontweight='bold', y=0.98)
        plt.tight_layout()
        
        # ä¿å­˜å›¾è¡¨
        summary_path = os.path.join(output_dir, "dataset_summary.png")
        plt.savefig(summary_path, dpi=150, bbox_inches='tight')
        plt.show()
        plt.close()
        
        print(f"æ•°æ®é›†æ€»ç»“å›¾è¡¨å·²ä¿å­˜åˆ°: {summary_path}")
        
        # ç”Ÿæˆæ–‡æœ¬æ€»ç»“
        txt_summary = f"""
        ========================================
        å£°å‘ä»¿çœŸæ•°æ®é›†æ€»ç»“æŠ¥å‘Š
        ========================================
        ç”Ÿæˆæ—¶é—´: {dataset_info.get('creation_date', 'N/A')}
        æ€»æ ·æœ¬æ•°: {dataset_info.get('total_samples', 0)}
        
        å±‚æ•°ç»Ÿè®¡:
          å¹³å‡å±‚æ•°: {np.mean(num_layers_list):.2f}
          æœ€å°å±‚æ•°: {np.min(num_layers_list)}
          æœ€å¤§å±‚æ•°: {np.max(num_layers_list)}
        
        æ·±åº¦ç»Ÿè®¡:
          å¹³å‡æ·±åº¦: {np.mean(total_depth_list):.2f} m
          æœ€å°æ·±åº¦: {np.min(total_depth_list):.2f} m
          æœ€å¤§æ·±åº¦: {np.max(total_depth_list):.2f} m
        
        æ²‰ç§¯ç‰©ç±»å‹ç»Ÿè®¡:
        """
        
        for sed_type, count in sediment_counts.items():
            percentage = count / sum(sediment_counts.values()) * 100 if sum(sediment_counts.values()) > 0 else 0
            txt_summary += f"  {sed_type}: {count} æ¬¡ ({percentage:.1f}%)\n"
        
        if feature_counts:
            txt_summary += "\nåœ°è´¨ç‰¹å¾ç»Ÿè®¡:\n"
            for ftype, count in feature_counts.items():
                percentage = count / len(samples_metadata) * 100 if len(samples_metadata) > 0 else 0
                txt_summary += f"  {ftype}: {count} æ¬¡ ({percentage:.1f}%)\n"
        
        txt_summary += "\n" + "="*40 + "\n"
        
        # ä¿å­˜æ–‡æœ¬æ€»ç»“
        txt_path = os.path.join(output_dir, "dataset_summary.txt")
        with open(txt_path, 'w', encoding='utf-8') as f:
            f.write(txt_summary)
        
        print(f"æ–‡æœ¬æ€»ç»“å·²ä¿å­˜åˆ°: {txt_path}")
        print("\n" + txt_summary)

class SonarSimulationPipeline:
    """ä¿®å¤çš„å£°å‘ä»¿çœŸæµæ°´çº¿ - ä½¿ç”¨ç¡¬ç¼–ç é…ç½®"""
    
    def __init__(self, visualize_samples: bool = True, 
                 visualization_interval: int = 10):
        # ä½¿ç”¨ç¡¬ç¼–ç é…ç½®
        self.config = DEFAULT_CONFIG
        
        # å¯è§†åŒ–è®¾ç½®
        self.visualize_samples = visualize_samples
        self.visualization_interval = visualization_interval
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.sediment_gen = SedimentModelGenerator()
        self.acoustic_sim = AcousticSimulator(self.config)
        self.sensor_sim = SensorSimulator(self.config)
        self.data_aug = DataAugmentation(self.config)
        self.data_saver = DataSaver("training_data")
        self.visualizer = Visualizer()
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs("training_data", exist_ok=True)
        os.makedirs("visualization", exist_ok=True)
        
        # ç”¨äºå­˜å‚¨ç”Ÿæˆçš„æ ·æœ¬å…ƒæ•°æ®
        self.samples_metadata = []
    
    def generate_single_sample(self, sample_id: int) -> Dict[str, Any]:
        """ç”Ÿæˆå•ä¸ªè®­ç»ƒæ ·æœ¬"""
        # 1. ç”Ÿæˆåœ°è´¨æ¨¡å‹
        base_model = self.sediment_gen.generate_layered_model()
        model_with_features = self.sediment_gen.add_geological_features(base_model)
        
        # 2. ç”Ÿæˆåå°„ç³»æ•°åºåˆ—
        reflection_series = self.sediment_gen.generate_reflection_coefficients(model_with_features)
        
        # 3. ç”Ÿæˆå£°å­¦å“åº”
        clean_trace = self.acoustic_sim.convolutional_model(reflection_series)
        
        # 4. æ·»åŠ ä¼ æ„Ÿå™¨æ•ˆåº”å’Œå™ªå£°
        noisy_trace = self.sensor_sim.add_noise(clean_trace)
        
        # 5. ç”Ÿæˆæ ‡æ³¨
        segmentation_mask = self.sediment_gen.generate_segmentation_mask(model_with_features)
        
        # 6. æ•°æ®å¢å¼º
        augmented_trace, augmented_mask = self.data_aug.apply_augmentation(
            noisy_trace, segmentation_mask
        )
        
        # å‡†å¤‡å…ƒæ•°æ®
        metadata = {
            'sample_id': sample_id,
            'model_id': model_with_features['model_id'],
            'num_layers': len(model_with_features['layers']),
            'total_depth': model_with_features['total_depth'],
            'layer_info': model_with_features['layers'],
            'features': model_with_features.get('features', [])
        }
        
        # å­˜å‚¨å…ƒæ•°æ®ç”¨äºåç»­ç»Ÿè®¡
        self.samples_metadata.append(metadata)
        
        # å¯è§†åŒ–æ ·æœ¬ï¼ˆæ¯éš”ä¸€å®šé—´éš”ï¼‰
        if self.visualize_samples and sample_id % self.visualization_interval == 0:
            sample_data = {
                'data': augmented_trace,
                'labels': augmented_mask,
                'metadata': metadata
            }
            
            # ä¿å­˜å¯è§†åŒ–å›¾è¡¨
            viz_path = os.path.join("visualization", f"sample_{sample_id:06d}.png")
            self.visualizer.plot_single_sample(sample_data, sample_id, viz_path)
        
        return {
            'data': augmented_trace,
            'labels': augmented_mask,
            'metadata': metadata
        }
    
    def generate_dataset(self, num_samples: int = 100):
        """ç”Ÿæˆå®Œæ•´æ•°æ®é›†"""
        # é‡ç½®å…ƒæ•°æ®åˆ—è¡¨
        self.samples_metadata = []
        
        dataset_info = {
            'total_samples': num_samples,
            'creation_date': str(np.datetime64('now'))
        }
        
        # ç”Ÿæˆè¿›åº¦æ¡
        progress_bar = tqdm(range(num_samples), desc="ç”Ÿæˆæ ·æœ¬")
        
        for i in progress_bar:
            sample = self.generate_single_sample(i)
            
            # æ›´æ–°è¿›åº¦æ¡æè¿°
            metadata = sample['metadata']
            progress_bar.set_postfix({
                'å±‚æ•°': metadata['num_layers'],
                'æ·±åº¦': f"{metadata['total_depth']:.1f}m",
                'ç‰¹å¾æ•°': len(metadata.get('features', []))
            })
            
            # ä¿å­˜æ ·æœ¬
            filename = f"sample_{i:06d}"
            self.data_saver.save_training_sample(
                sample['data'], sample['labels'], sample['metadata'], filename
            )
        
        # ä¿å­˜æ•°æ®é›†ä¿¡æ¯
        self.data_saver.save_dataset_info(dataset_info)
        
        # ç”Ÿæˆæ•°æ®é›†æ€»ç»“å›¾è¡¨
        print("\n" + "="*60)
        print("ç”Ÿæˆæ•°æ®é›†æ€»ç»“å›¾è¡¨...")
        print("="*60)
        
        try:
            self.visualizer.plot_dataset_summary(dataset_info, self.samples_metadata)
        except Exception as e:
            print(f"ç”Ÿæˆæ€»ç»“å›¾è¡¨æ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
        
        print(f"\n{'='*60}")
        print(f"æ•°æ®é›†ç”Ÿæˆå®Œæˆï¼å…± {num_samples} ä¸ªæ ·æœ¬")
        print(f"æ•°æ®ä¿å­˜ç›®å½•: training_data/")
        print(f"å¯è§†åŒ–å›¾è¡¨ç›®å½•: visualization/")
        print(f"{'='*60}")
        
        # ç”Ÿæˆå®Œæˆæç¤º
        self._print_completion_message(num_samples)
    
    def _print_completion_message(self, num_samples: int):
        """æ‰“å°å®Œæˆä¿¡æ¯"""
        completion_msg = f"""
        ğŸ‰ å£°å‘ä»¿çœŸæ•°æ®é›†ç”Ÿæˆå®Œæˆï¼
        
        ç»Ÿè®¡ä¿¡æ¯:
        ğŸ“Š æ€»æ ·æœ¬æ•°: {num_samples}
        ğŸ“ æ•°æ®ç›®å½•: training_data/
        ğŸ–¼ï¸  å›¾è¡¨ç›®å½•: visualization/
        
        ä¸‹ä¸€æ­¥å»ºè®®:
        1. æŸ¥çœ‹ visualization/dataset_summary.png äº†è§£æ•°æ®é›†æ¦‚å†µ
        2. æ£€æŸ¥ visualization/sample_*.png æŸ¥çœ‹å…·ä½“æ ·æœ¬
        3. ä½¿ç”¨ç”Ÿæˆçš„è®­ç»ƒæ•°æ®è®­ç»ƒæ‚¨çš„æ·±åº¦å­¦ä¹ æ¨¡å‹
        
        ç”Ÿæˆçš„æ ·æœ¬æ–‡ä»¶æ ¼å¼:
        â”œâ”€â”€ sample_000000.npy      # å£°å‘æ•°æ®
        â”œâ”€â”€ sample_000000_labels.npy # æ ‡æ³¨æ•°æ®
        â””â”€â”€ sample_000000_metadata.npy # å…ƒæ•°æ®
        """
        
        print(completion_msg)

def test_visualization():
    """æµ‹è¯•å¯è§†åŒ–åŠŸèƒ½"""
    print("æµ‹è¯•å¯è§†åŒ–åŠŸèƒ½...")
    print("="*60)
    
    # åˆ›å»ºä¸´æ—¶æ ·æœ¬ç”¨äºæµ‹è¯•
    sample = {
        'data': np.sin(np.linspace(0, 10, DEFAULT_CONFIG['simulation']['trace_length'])) + \
                np.random.normal(0, 0.1, DEFAULT_CONFIG['simulation']['trace_length']),
        'labels': np.random.choice([0, 1, 2, 3, 4, 6], DEFAULT_CONFIG['simulation']['trace_length'], 
                                  p=[0.6, 0.1, 0.1, 0.1, 0.05, 0.05]),
        'metadata': {
            'sample_id': 999,
            'model_id': 'test_model_001',
            'num_layers': 5,
            'total_depth': 12.5,
            'layer_info': [
                {'sediment_type': 'clay', 'thickness': 2.0, 'density': 1600, 'velocity': 1500},
                {'sediment_type': 'silt', 'thickness': 3.0, 'density': 1750, 'velocity': 1600},
                {'sediment_type': 'sand', 'thickness': 2.5, 'density': 1950, 'velocity': 1700},
                {'sediment_type': 'gravel', 'thickness': 3.0, 'density': 2100, 'velocity': 2000},
                {'sediment_type': 'mixed', 'thickness': 2.0, 'density': 1800, 'velocity': 1650}
            ],
            'features': [
                {'type': 'gas_pocket', 'depth': 4.5, 'intensity': 0.7},
                {'type': 'buried_object', 'depth': 8.2, 'object_type': 'metal'}
            ]
        }
    }
    
    # æ˜¾ç¤ºå•ä¸ªæ ·æœ¬å¯è§†åŒ–
    Visualizer.plot_single_sample(sample, sample_id=999)
    
    # æµ‹è¯•æ•°æ®é›†æ€»ç»“
    dataset_info = {
        'total_samples': 50,
        'creation_date': '2024-01-15'
    }
    
    samples_metadata = [
        {'num_layers': 3, 'total_depth': 8.5, 'layer_info': [{'sediment_type': 'clay'}]},
        {'num_layers': 5, 'total_depth': 12.2, 'layer_info': [{'sediment_type': 'sand'}]},
        {'num_layers': 4, 'total_depth': 10.1, 'layer_info': [{'sediment_type': 'silt'}]},
        {'num_layers': 6, 'total_depth': 15.3, 'layer_info': [{'sediment_type': 'gravel'}]},
        {'num_layers': 4, 'total_depth': 9.8, 'layer_info': [{'sediment_type': 'mixed'}]},
    ]
    
    print("æµ‹è¯•å®Œæˆ!")

if __name__ == "__main__":
    print("å£°å‘ä»¿çœŸæ•°æ®ç”Ÿæˆç³»ç»Ÿ")
    print("="*60)
    
    # ç”¨æˆ·é€‰æ‹©
    print("è¯·é€‰æ‹©è¿è¡Œæ¨¡å¼:")
    print("1. ç”Ÿæˆå®Œæ•´æ•°æ®é›†")
    print("2. æµ‹è¯•å¯è§†åŒ–åŠŸèƒ½")
    print("3. è‡ªå®šä¹‰é…ç½®ç”Ÿæˆ")
    print("4. ä»…ç”Ÿæˆå°‘é‡æ ·æœ¬æµ‹è¯•")
    
    try:
        choice = input("è¯·è¾“å…¥é€‰æ‹© (1-4): ").strip()
    except EOFError:
        # å¦‚æœæ˜¯ä»è„šæœ¬è°ƒç”¨ï¼Œä½¿ç”¨é»˜è®¤å€¼
        choice = "1"
    
    if choice == "1":
        # ç”Ÿæˆå®Œæ•´æ•°æ®é›†
        try:
            num_samples_input = input("è¯·è¾“å…¥è¦ç”Ÿæˆçš„æ ·æœ¬æ•°é‡ (é»˜è®¤50): ").strip()
            num_samples = int(num_samples_input) if num_samples_input else 50
        except:
            num_samples = 50
            
        try:
            interval_input = input("å¯è§†åŒ–é—´éš” (æ¯å¤šå°‘ä¸ªæ ·æœ¬æ˜¾ç¤ºä¸€æ¬¡ï¼Œé»˜è®¤10): ").strip()
            visualize_interval = int(interval_input) if interval_input else 10
        except:
            visualize_interval = 10
        
        pipeline = SonarSimulationPipeline(
            visualize_samples=True,
            visualization_interval=visualize_interval
        )
        
        print(f"\nå¼€å§‹ç”Ÿæˆ {num_samples} ä¸ªæ ·æœ¬çš„æ•°æ®é›†...")
        pipeline.generate_dataset(num_samples=num_samples)
        
    elif choice == "2":
        # æµ‹è¯•å¯è§†åŒ–
        test_visualization()
        
    elif choice == "3":
        # è‡ªå®šä¹‰é…ç½®
        print("è‡ªå®šä¹‰é…ç½®åŠŸèƒ½æš‚æœªå®ç°ï¼Œä½¿ç”¨é»˜è®¤é…ç½®...")
        
        try:
            num_samples_input = input("è¯·è¾“å…¥æ ·æœ¬æ•°é‡: ").strip()
            num_samples = int(num_samples_input) if num_samples_input else 10
        except:
            num_samples = 10
            
        try:
            interval_input = input("å¯è§†åŒ–é—´éš”: ").strip()
            visualize_interval = int(interval_input) if interval_input else 5
        except:
            visualize_interval = 5
        
        pipeline = SonarSimulationPipeline(
            visualize_samples=True,
            visualization_interval=visualize_interval
        )
        
        print(f"\nå¼€å§‹ç”Ÿæˆ {num_samples} ä¸ªæ ·æœ¬çš„æ•°æ®é›†...")
        pipeline.generate_dataset(num_samples=num_samples)
        
    elif choice == "4":
        # ä»…ç”Ÿæˆå°‘é‡æ ·æœ¬æµ‹è¯•
        print("\nç”Ÿæˆå°‘é‡æ ·æœ¬è¿›è¡Œæµ‹è¯•...")
        pipeline = SonarSimulationPipeline(
            visualize_samples=True,
            visualization_interval=1  # æ¯ä¸ªæ ·æœ¬éƒ½å¯è§†åŒ–
        )
        pipeline.generate_dataset(num_samples=5)
        
    else:
        print("æ— æ•ˆé€‰æ‹©ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å¼...")
        pipeline = SonarSimulationPipeline()
        pipeline.generate_dataset(num_samples=10)